{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf7bb76",
   "metadata": {},
   "source": [
    "Compute PSNR, SSIM, LPIPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2594b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lpips\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beccc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error\n",
    "class MSE(object):\n",
    "    def __call__(self, pred, gt):\n",
    "        return torch.mean((pred - gt) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e54bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak Signal to Noise Ratio\n",
    "class PSNR(object):\n",
    "    def __call__(self, pred, gt):\n",
    "        mse = torch.mean((pred - gt) ** 2)\n",
    "        return 10 * torch.log10(1 / mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94269892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structural similarity index\n",
    "class SSIM(object):\n",
    "    '''\n",
    "    borrowed from https://github.com/huster-wgm/Pytorch-metrics/blob/master/metrics.py\n",
    "    '''\n",
    "    def gaussian(self, w_size, sigma):\n",
    "        gauss = torch.Tensor([math.exp(-(x - w_size//2)**2/float(2*sigma**2)) for x in range(w_size)])\n",
    "        return gauss/gauss.sum()\n",
    "\n",
    "    def create_window(self, w_size, channel=1):\n",
    "        _1D_window = self.gaussian(w_size, 1.5).unsqueeze(1)\n",
    "        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "        window = _2D_window.expand(channel, 1, w_size, w_size).contiguous()\n",
    "        return window\n",
    "\n",
    "    def __call__(self, y_pred, y_true, w_size=11, size_average=True, full=False):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            y_true : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            y_pred : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            w_size : int, default 11\n",
    "            size_average : boolean, default True\n",
    "            full : boolean, default False\n",
    "        return ssim, larger the better\n",
    "        \"\"\"\n",
    "        # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
    "        if torch.max(y_pred) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    "\n",
    "        if torch.min(y_pred) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "\n",
    "        padd = 0\n",
    "        (_, channel, height, width) = y_pred.size()\n",
    "        window = self.create_window(w_size, channel=channel).to(y_pred.device)\n",
    "\n",
    "        mu1 = F.conv2d(y_pred, window, padding=padd, groups=channel)\n",
    "        mu2 = F.conv2d(y_true, window, padding=padd, groups=channel)\n",
    "\n",
    "        mu1_sq = mu1.pow(2)\n",
    "        mu2_sq = mu2.pow(2)\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.conv2d(y_pred * y_pred, window, padding=padd, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(y_true * y_true, window, padding=padd, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(y_pred * y_true, window, padding=padd, groups=channel) - mu1_mu2\n",
    "\n",
    "        C1 = (0.01 * L) ** 2\n",
    "        C2 = (0.03 * L) ** 2\n",
    "\n",
    "        v1 = 2.0 * sigma12 + C2\n",
    "        v2 = sigma1_sq + sigma2_sq + C2\n",
    "        cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
    "\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    "\n",
    "        if size_average:\n",
    "            ret = ssim_map.mean()\n",
    "        else:\n",
    "            ret = ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "        if full:\n",
    "            return ret, cs\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a37b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned Perceptual Image Patch Similarity\n",
    "class LPIPS(object):\n",
    "    '''\n",
    "    borrowed from https://github.com/huster-wgm/Pytorch-metrics/blob/master/metrics.py\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.model = lpips.LPIPS(net='vgg').cuda()\n",
    "\n",
    "    def __call__(self, y_pred, y_true, normalized=True):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            y_true : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            y_pred : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            normalized : change [0,1] => [-1,1] (default by LPIPS)\n",
    "        return LPIPS, smaller the better\n",
    "        \"\"\"\n",
    "        if normalized:\n",
    "            y_pred = y_pred * 2.0 - 1.0\n",
    "            y_true = y_true * 2.0 - 1.0\n",
    "        error =  self.model.forward(y_pred, y_true)\n",
    "        return torch.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52160fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_error(estim, gt):\n",
    "    errors = dict()\n",
    "    metric = MSE()\n",
    "    errors[\"mse\"] = metric(estim, gt).item()\n",
    "    metric = PSNR()\n",
    "    errors[\"psnr\"] = metric(estim, gt).item()\n",
    "    metric = SSIM()\n",
    "    errors[\"ssim\"] = metric(estim, gt).item()\n",
    "    metric = LPIPS()\n",
    "    errors[\"lpips\"] = metric(estim, gt).item()\n",
    "    return errors\n",
    "\n",
    "def save_error(errors, save_dir):\n",
    "    save_path = os.path.join(save_dir, \"metrics.txt\")\n",
    "    f = open(save_path,\"w\")\n",
    "    f.write( str(errors) )\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147e5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_in_dir(imgs_dir, rollout=False):\n",
    "    imgs = []\n",
    "    if rollout:\n",
    "        fnames = sorted(glob.glob(os.path.join(imgs_dir, '*.png')))[-10:]\n",
    "    else:\n",
    "        fnames = sorted(glob.glob(os.path.join(imgs_dir, '*.png')))[:-10]\n",
    "    # fnames = sorted(glob.glob(os.path.join(imgs_dir, '*.png')))\n",
    "    print(len(fnames))\n",
    "    fnames.sort(key=lambda x:int(x.split('/')[-1][:-4]))\n",
    "    for fname in fnames:\n",
    "        img_path = fname\n",
    "        img = imageio.imread(img_path)\n",
    "        img = (np.array(img) / 255.).astype(np.float32)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        imgs.append(img)\n",
    "    imgs = np.stack(imgs)       \n",
    "    return imgs\n",
    "\n",
    "def read_image_in_path(img_path):\n",
    "    # img_path = fname\n",
    "    img = imageio.imread(img_path)\n",
    "    img = (np.array(img) / 255.).astype(np.float32)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return img[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3672af9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/syguan/.conda/envs/open3d/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "psnr 28.899144172668457\n",
      "ssim 0.9334042549133301\n",
      "lpips 0.1303511880338192\n",
      "{'psnr': [[32.31077575683594, 31.61586570739746, 30.601701736450195, 29.700759887695312, 28.856718063354492, 28.17063331604004, 27.560935974121094, 27.113733291625977, 26.71978759765625, 26.340530395507812]], 'ssim': [[0.9519639015197754, 0.9478753209114075, 0.9426882266998291, 0.9370866417884827, 0.9331207275390625, 0.9305313229560852, 0.9272639751434326, 0.9242094159126282, 0.92047518491745, 0.9188278317451477]], 'lpips': [[0.11537817120552063, 0.11974865198135376, 0.12150127440690994, 0.12547677755355835, 0.12817786633968353, 0.13120457530021667, 0.13521189987659454, 0.1377238780260086, 0.1436430960893631, 0.14544568955898285]]}\n"
     ]
    }
   ],
   "source": [
    "rollout = True\n",
    "RES_DIR = '/data/syguan/fluid_simulation/release/code/eval_res/ablation-nn/hpc/wo-smoothed_dir/images/fine'\n",
    "views = ['view_6']\n",
    "\n",
    "all_erros = {'psnr':[], 'ssim':[], 'lpips':[]}\n",
    "\n",
    "for view in views:\n",
    "    files_dir = f'{RES_DIR}/{view}'\n",
    "    gt_dir = os.path.join(files_dir, 'GT')\n",
    "    pred_dir = os.path.join(files_dir, 'Pred')\n",
    "        \n",
    "    gt = read_images_in_dir(gt_dir,rollout=rollout)\n",
    "    pred = read_images_in_dir(pred_dir,rollout=rollout)\n",
    "\n",
    "    gt = torch.tensor(gt).cuda()\n",
    "    pred = torch.tensor(pred).cuda()\n",
    "    \n",
    "    #----> if OOM\n",
    "    errors = {'lpips':[], 'psnr':[], 'ssim':[]}\n",
    "    for i in range(gt.shape[0]):\n",
    "        gt_, pred_ = gt[i, None], pred[i, None]\n",
    "        error = estim_error(pred_, gt_)\n",
    "        for k,v in error.items():\n",
    "            if k in all_erros:\n",
    "                errors[k].append(v)\n",
    "    #----> if OOM\n",
    "                \n",
    "    #----> for faster computation\n",
    "    # with torch.no_grad():\n",
    "    #     errors = estim_error(pred, gt)\n",
    "    #----> for faster computation\n",
    "    \n",
    "    save_error(errors, files_dir)\n",
    "    \n",
    "    for k,v in errors.items():\n",
    "        if k in all_erros:\n",
    "            all_erros[k].append(v)\n",
    "for k,v in all_erros.items():\n",
    "    print(k, np.mean(v))\n",
    "print(all_erros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('fluid-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "309523888c02639b33d448713d1dd028a2c241f372fa34df70b184077d2aafe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
