{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf7bb76",
   "metadata": {},
   "source": [
    "Compute PSNR, SSIM, LPIPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2594b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lpips\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beccc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error\n",
    "class MSE(object):\n",
    "    def __call__(self, pred, gt):\n",
    "        return torch.mean((pred - gt) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e54bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak Signal to Noise Ratio\n",
    "class PSNR(object):\n",
    "    def __call__(self, pred, gt):\n",
    "        mse = torch.mean((pred - gt) ** 2)\n",
    "        return 10 * torch.log10(1 / mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94269892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structural similarity index\n",
    "class SSIM(object):\n",
    "    '''\n",
    "    borrowed from https://github.com/huster-wgm/Pytorch-metrics/blob/master/metrics.py\n",
    "    '''\n",
    "    def gaussian(self, w_size, sigma):\n",
    "        gauss = torch.Tensor([math.exp(-(x - w_size//2)**2/float(2*sigma**2)) for x in range(w_size)])\n",
    "        return gauss/gauss.sum()\n",
    "\n",
    "    def create_window(self, w_size, channel=1):\n",
    "        _1D_window = self.gaussian(w_size, 1.5).unsqueeze(1)\n",
    "        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "        window = _2D_window.expand(channel, 1, w_size, w_size).contiguous()\n",
    "        return window\n",
    "\n",
    "    def __call__(self, y_pred, y_true, w_size=11, size_average=True, full=False):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            y_true : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            y_pred : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            w_size : int, default 11\n",
    "            size_average : boolean, default True\n",
    "            full : boolean, default False\n",
    "        return ssim, larger the better\n",
    "        \"\"\"\n",
    "        # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
    "        if torch.max(y_pred) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    "\n",
    "        if torch.min(y_pred) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "\n",
    "        padd = 0\n",
    "        (_, channel, height, width) = y_pred.size()\n",
    "        window = self.create_window(w_size, channel=channel).to(y_pred.device)\n",
    "\n",
    "        mu1 = F.conv2d(y_pred, window, padding=padd, groups=channel)\n",
    "        mu2 = F.conv2d(y_true, window, padding=padd, groups=channel)\n",
    "\n",
    "        mu1_sq = mu1.pow(2)\n",
    "        mu2_sq = mu2.pow(2)\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.conv2d(y_pred * y_pred, window, padding=padd, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(y_true * y_true, window, padding=padd, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(y_pred * y_true, window, padding=padd, groups=channel) - mu1_mu2\n",
    "\n",
    "        C1 = (0.01 * L) ** 2\n",
    "        C2 = (0.03 * L) ** 2\n",
    "\n",
    "        v1 = 2.0 * sigma12 + C2\n",
    "        v2 = sigma1_sq + sigma2_sq + C2\n",
    "        cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
    "\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    "\n",
    "        if size_average:\n",
    "            ret = ssim_map.mean()\n",
    "        else:\n",
    "            ret = ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "        if full:\n",
    "            return ret, cs\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a37b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned Perceptual Image Patch Similarity\n",
    "class LPIPS(object):\n",
    "    '''\n",
    "    borrowed from https://github.com/huster-wgm/Pytorch-metrics/blob/master/metrics.py\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.model = lpips.LPIPS(net='vgg').cuda()\n",
    "\n",
    "    def __call__(self, y_pred, y_true, normalized=True):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            y_true : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            y_pred : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            normalized : change [0,1] => [-1,1] (default by LPIPS)\n",
    "        return LPIPS, smaller the better\n",
    "        \"\"\"\n",
    "        if normalized:\n",
    "            y_pred = y_pred * 2.0 - 1.0\n",
    "            y_true = y_true * 2.0 - 1.0\n",
    "        error =  self.model.forward(y_pred, y_true)\n",
    "        return torch.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52160fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_error(estim, gt):\n",
    "    errors = dict()\n",
    "    metric = MSE()\n",
    "    errors[\"mse\"] = metric(estim, gt).item()\n",
    "    metric = PSNR()\n",
    "    errors[\"psnr\"] = metric(estim, gt).item()\n",
    "    metric = SSIM()\n",
    "    errors[\"ssim\"] = metric(estim, gt).item()\n",
    "    metric = LPIPS()\n",
    "    errors[\"lpips\"] = metric(estim, gt).item()\n",
    "    return errors\n",
    "\n",
    "def save_error(errors, save_dir):\n",
    "    save_path = os.path.join(save_dir, \"metrics.txt\")\n",
    "    f = open(save_path,\"w\")\n",
    "    f.write( str(errors) )\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147e5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_in_dir(imgs_dir, rollout=False):\n",
    "    imgs = []\n",
    "    if rollout:\n",
    "        fnames = sorted(glob.glob(os.path.join(imgs_dir, '*.png')))[-10:]\n",
    "    else:\n",
    "        fnames = sorted(glob.glob(os.path.join(imgs_dir, '*.png')))[:-10]\n",
    "    # fnames = sorted(glob.glob(os.path.join(imgs_dir, '*.png')))\n",
    "    print(len(fnames))\n",
    "    fnames.sort(key=lambda x:int(x.split('/')[-1][:-4]))\n",
    "    for fname in fnames:\n",
    "        img_path = fname\n",
    "        img = imageio.imread(img_path)\n",
    "        img = (np.array(img) / 255.).astype(np.float32)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        imgs.append(img)\n",
    "    imgs = np.stack(imgs)       \n",
    "    return imgs\n",
    "\n",
    "def read_image_in_path(img_path):\n",
    "    # img_path = fname\n",
    "    img = imageio.imread(img_path)\n",
    "    img = (np.array(img) / 255.).astype(np.float32)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return img[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3672af9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  if sys.path[0] == \"\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/rayne/anaconda3/envs/py3.7/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "psnr 20.345989799499513\n",
      "ssim 0.8986683070659638\n",
      "lpips 0.22549542039632797\n",
      "{'psnr': [[21.203136444091797, 21.017549514770508, 20.84933090209961, 20.686126708984375, 20.492923736572266, 20.274019241333008, 20.038589477539062, 19.83356475830078, 19.630144119262695, 19.434513092041016]], 'ssim': [[0.9097487926483154, 0.9074796438217163, 0.9044098258018494, 0.9016326069831848, 0.8994433283805847, 0.8974915146827698, 0.8960531949996948, 0.8933858275413513, 0.8896186351776123, 0.8874197006225586]], 'lpips': [[0.2190011441707611, 0.22142937779426575, 0.2215965986251831, 0.2212902307510376, 0.224424347281456, 0.2253684401512146, 0.226019948720932, 0.22986993193626404, 0.23157554864883423, 0.2343786358833313]]}\n"
     ]
    }
   ],
   "source": [
    "rollout = True\n",
    "RES_DIR = 'exps/eval/e2e_nf2_volsdfsampling/images/coarse'\n",
    "views = ['view_5']\n",
    "\n",
    "all_erros = {'psnr':[], 'ssim':[], 'lpips':[]}\n",
    "\n",
    "for view in views:\n",
    "    files_dir = f'{RES_DIR}/{view}'\n",
    "    gt_dir = os.path.join(files_dir, 'GT')\n",
    "    pred_dir = os.path.join(files_dir, 'Pred')\n",
    "        \n",
    "    gt = read_images_in_dir(gt_dir,rollout=rollout)\n",
    "    pred = read_images_in_dir(pred_dir,rollout=rollout)\n",
    "\n",
    "    gt = torch.tensor(gt).cuda()\n",
    "    pred = torch.tensor(pred).cuda()\n",
    "    \n",
    "    #----> if OOM\n",
    "    errors = {'lpips':[], 'psnr':[], 'ssim':[]}\n",
    "    for i in range(gt.shape[0]):\n",
    "        gt_, pred_ = gt[i, None], pred[i, None]\n",
    "        error = estim_error(pred_, gt_)\n",
    "        for k,v in error.items():\n",
    "            if k in all_erros:\n",
    "                errors[k].append(v)\n",
    "    #----> if OOM\n",
    "                \n",
    "    #----> for faster computation\n",
    "    # with torch.no_grad():\n",
    "    #     errors = estim_error(pred, gt)\n",
    "    #----> for faster computation\n",
    "    \n",
    "    save_error(errors, files_dir)\n",
    "    \n",
    "    for k,v in errors.items():\n",
    "        if k in all_erros:\n",
    "            all_erros[k].append(v)\n",
    "for k,v in all_erros.items():\n",
    "    print(k, np.mean(v))\n",
    "print(all_erros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "21137cca9002bd8342206d8adaed4cccebabfe3e876edeeeb1ecc865ab1cba7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
